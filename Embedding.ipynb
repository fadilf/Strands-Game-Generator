{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import pickle\n",
    "from scipy.spatial import KDTree\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_cont_set(word, n):\n",
    "    n_letters_word = set()\n",
    "    for i in range(len(word) - n + 1):\n",
    "        n_letters_word.add(word[i:i+n])\n",
    "    return n_letters_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shares_n_cont_letters(a: str, b: str, n: int):\n",
    "    n_letters_a = set()\n",
    "    for i in range(len(a) - n + 1):\n",
    "        n_letters_a.add(a[i:i+n])\n",
    "\n",
    "    for i in range(len(b) - n + 1):\n",
    "        if b[i:i+n] in n_letters_a:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_grid(grid):\n",
    "    return [[tuple(item) for item in row] for row in np.rot90(np.array(grid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlagModel('BAAI/bge-small-en-v1.5',\n",
    "                  query_instruction_for_retrieval=\"Generate a representation for this word for retrieving related words:\",\n",
    "                  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"google-10000-english-no-swears.txt\") as f:\n",
    "    all_words = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9894"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in all_words:\n",
    "    word_filtered = word.strip()\n",
    "    if len(word_filtered) > 3:\n",
    "        words.append(word_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 35/35 [00:10<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = {}\n",
    "for word in words:\n",
    "    word_len = len(word)\n",
    "    if word_len not in lens:\n",
    "        lens[word_len] = 1\n",
    "    else:\n",
    "        lens[word_len] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1100,\n",
       " 5: 1367,\n",
       " 6: 1491,\n",
       " 11: 374,\n",
       " 7: 1449,\n",
       " 8: 1157,\n",
       " 9: 904,\n",
       " 10: 608,\n",
       " 13: 101,\n",
       " 12: 207,\n",
       " 14: 39,\n",
       " 15: 10,\n",
       " 18: 1,\n",
       " 16: 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"embeddings.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(embeddings, f)\n",
    "with open(\"embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8810, 384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Photography\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1000 most relevant words/phrases\n",
    "dd, ii = tree.query(query_embedding, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose spangrammables\n",
    "spangrammable = []\n",
    "for i in ii:\n",
    "    candidate = words[i].strip()\n",
    "    candidate_alpha_only = \"\".join([char for char in candidate if char.isalpha()])\n",
    "    if 6 <= len(candidate_alpha_only) <= 13:\n",
    "        spangrammable.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recordings'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spangram = random.choice(spangrammable[:100])\n",
    "spangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "subembeddings = [embeddings[i] for i in ii]\n",
    "subwords = [words[i] for i in ii]\n",
    "subtree = KDTree(subembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words/phrases the most relevant to spangram\n",
    "ddd, iii = subtree.query(model.encode(spangram), k=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates: list[str] = []\n",
    "n = 4\n",
    "candidate_n_cont_pool: set[str] = set()\n",
    "for i in iii:\n",
    "    word = subwords[i].strip().lower()\n",
    "    word_set = generate_n_cont_set(word, n)\n",
    "    unique = True\n",
    "    for item in word_set:\n",
    "        if item in candidate_n_cont_pool:\n",
    "            unique = False\n",
    "            break\n",
    "    if unique:\n",
    "        candidates.append(word)\n",
    "        candidate_n_cont_pool.update(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recordings',\n",
       " 'audio',\n",
       " 'tapes',\n",
       " 'footage',\n",
       " 'voices',\n",
       " 'albums',\n",
       " 'samples',\n",
       " 'videos',\n",
       " 'listening',\n",
       " 'documents',\n",
       " 'songs',\n",
       " 'photographs',\n",
       " 'clips',\n",
       " 'music',\n",
       " 'vids',\n",
       " 'sound',\n",
       " 'sessions',\n",
       " 'cameras',\n",
       " 'performing',\n",
       " 'tracks',\n",
       " 'stories',\n",
       " 'reproduced',\n",
       " 'gallery',\n",
       " 'files',\n",
       " 'media',\n",
       " 'singing',\n",
       " 'collection',\n",
       " 'press',\n",
       " 'acoustic',\n",
       " 'streams',\n",
       " 'pictures',\n",
       " 'papers',\n",
       " 'lessons',\n",
       " 'images',\n",
       " 'microphone',\n",
       " 'experiences',\n",
       " 'highlights',\n",
       " 'journals',\n",
       " 'reporters',\n",
       " 'artists',\n",
       " 'outputs',\n",
       " 'speech',\n",
       " 'diary',\n",
       " 'observe',\n",
       " 'techniques',\n",
       " 'source',\n",
       " 'scenes',\n",
       " 'livecam',\n",
       " 'uploaded',\n",
       " 'browse',\n",
       " 'vocal',\n",
       " 'mpegs',\n",
       " 'films',\n",
       " 'snapshot',\n",
       " 'noise',\n",
       " 'watching',\n",
       " 'slides',\n",
       " 'during',\n",
       " 'oral',\n",
       " 'webcams',\n",
       " 'poems',\n",
       " 'show',\n",
       " 'tour',\n",
       " 'exhibits',\n",
       " 'prints',\n",
       " 'arrivals',\n",
       " 'labels',\n",
       " 'recent',\n",
       " 'thumbnails',\n",
       " 'stereo',\n",
       " 'fotos',\n",
       " 'these',\n",
       " 'examines',\n",
       " 'surveillance',\n",
       " 'from',\n",
       " 'data',\n",
       " 'library',\n",
       " 'pulse',\n",
       " 'accessed',\n",
       " 'draws',\n",
       " 'practice',\n",
       " 'texts',\n",
       " 'remarks',\n",
       " 'memory',\n",
       " 'viewer',\n",
       " 'narrative',\n",
       " 'publicly',\n",
       " 'more',\n",
       " 'tones',\n",
       " 'reel',\n",
       " 'waves',\n",
       " 'trips',\n",
       " 'scanners',\n",
       " 'bytes',\n",
       " 'content',\n",
       " 'each',\n",
       " 'postcards',\n",
       " 'maps',\n",
       " 'titled',\n",
       " 'learn',\n",
       " 'transparency',\n",
       " 'olympus',\n",
       " 'current',\n",
       " 'kodak',\n",
       " 'poetry',\n",
       " 'update',\n",
       " 'filter',\n",
       " 'artwork',\n",
       " 'result',\n",
       " 'subjects',\n",
       " 'their',\n",
       " 'prayers',\n",
       " 'sends',\n",
       " 'methods',\n",
       " 'pens']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the candidates into plain words and phrases\n",
    "plain_words = []\n",
    "phrases = []\n",
    "for candidate in candidates[1:]:\n",
    "    if len(candidate) <= 3:\n",
    "        continue\n",
    "    if candidate.isalpha():\n",
    "        plain_words.append(candidate)\n",
    "    else:\n",
    "        phrases.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_lengths = [len(plain_word) for plain_word in plain_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recordings'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spangram = \"\".join([char for char in spangram if char.isalpha()])\n",
    "spangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = (48 - len(spangram))//4\n",
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = random.choice(list(range(6, max_words + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 48 - len(spangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = []\n",
    "plain_lengths_cpy = plain_lengths[:]\n",
    "while sum(chosen) != budget:\n",
    "    remaining = budget - sum(chosen)\n",
    "    if sum(chosen) < budget:\n",
    "        if remaining in plain_lengths_cpy:\n",
    "            chosen.append(remaining)\n",
    "            break\n",
    "        else:\n",
    "            new_chosen = random.choice(plain_lengths_cpy)\n",
    "            plain_lengths_cpy.remove(new_chosen)\n",
    "            chosen.append(new_chosen)\n",
    "    elif sum(chosen) > budget:\n",
    "        if (-remaining) in chosen:\n",
    "            chosen.remove(-remaining)\n",
    "            break\n",
    "        else:\n",
    "            for i in range(random.choice([1,1,1,2,2,3])):\n",
    "                to_remove = random.choice(chosen)\n",
    "                chosen.remove(to_remove)\n",
    "                plain_lengths_cpy.append(to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 7, 12, 5, 6]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lens: dict[int, list[str]] = {}\n",
    "for word in plain_words:\n",
    "    word_len = len(word)\n",
    "    if word_len not in word_lens:\n",
    "        word_lens[word_len] = [word]\n",
    "    else:\n",
    "        word_lens[word_len].append(word)\n",
    "\n",
    "chosen_words = [spangram]\n",
    "for length in chosen:\n",
    "    chosen_word = random.choice(word_lens[length])\n",
    "    word_lens[length].remove(chosen_word)\n",
    "    chosen_words.append(chosen_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recordings', 'arrivals', 'footage', 'transparency', 'pulse', 'slides']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(spangram) < 8:\n",
    "    spangram_direction = \"ltr\"\n",
    "else:\n",
    "    spangram_direction = random.choice([\"ltr\", \"ttb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ltr'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spangram_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1 - COIL\n",
    "# grid = []\n",
    "# for i in range(8):\n",
    "#     row = []\n",
    "#     for j in range(6):\n",
    "#         row.append((i,j))\n",
    "#     grid.append(row)\n",
    "\n",
    "# if spangram_direction == \"ttb\":\n",
    "#     grid = rotate_grid(grid)\n",
    "# coord_lst = grid.pop(0)\n",
    "# while len(grid) > 0:\n",
    "#     grid = rotate_grid(grid)\n",
    "#     coord_lst.extend(grid.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2 - SNAKE\n",
    "grid = []\n",
    "for i in range(8):\n",
    "    row = []\n",
    "    for j in range(6):\n",
    "        row.append((i,j))\n",
    "    grid.append(row)\n",
    "\n",
    "if spangram_direction == \"ttb\":\n",
    "    grid = rotate_grid(grid)\n",
    "coord_lst = grid.pop(0)\n",
    "row = 1\n",
    "while len(grid) > 0:\n",
    "    if row % 2 == 0:\n",
    "        coord_lst.extend(grid.pop(0))\n",
    "    else:\n",
    "        coord_lst.extend(reversed(grid.pop(0)))\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spangrams = chosen_words[:]\n",
    "non_spangrams.remove(spangram)\n",
    "valid_combos = []\n",
    "for n in range(len(non_spangrams) + 1):\n",
    "    for combo in itertools.combinations(non_spangrams, n):\n",
    "        prefix_len = sum([len(item) for item in combo])\n",
    "        if spangram_direction == \"ltr\":\n",
    "            dir_len = 6\n",
    "        else:\n",
    "            dir_len = 8\n",
    "        row_prefix_len = prefix_len % dir_len\n",
    "        if (row_prefix_len == 0) or ((row_prefix_len + len(spangram)) >= (2 * dir_len)):\n",
    "            valid_combos.append(combo)\n",
    "\n",
    "chosen_combo = list(random.choice(valid_combos[1:-1]))\n",
    "random.shuffle(chosen_combo)\n",
    "for word in chosen_combo:\n",
    "    non_spangrams.remove(word)\n",
    "random.shuffle(non_spangrams)\n",
    "chosen_words = chosen_combo + [spangram] + non_spangrams\n",
    "spangram_idx = chosen_words.index(spangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords: list[list[tuple[int,int]]] = []\n",
    "\n",
    "for word in chosen_words:\n",
    "    word_coords = []\n",
    "    for char in word:\n",
    "        word_coords.append(coord_lst.pop(0))\n",
    "    if random.choice([True, False]):\n",
    "        coords.append(word_coords)\n",
    "    else:\n",
    "        coords.append(list(reversed(word_coords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_letter_idx(coords, letter_coords, words):\n",
    "    for word_idx, word_coords in enumerate(coords):\n",
    "        if letter_coords in word_coords:\n",
    "            letter_idx = word_coords.index(letter_coords)\n",
    "            word = words[word_idx]\n",
    "            letter = word[letter_idx]\n",
    "            return letter_idx, letter, word_idx, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_continuity(word_coords:list[list[tuple[int,int]]]):\n",
    "    for coords_a, coords_b in zip(word_coords[:-1], word_coords[1:]):\n",
    "        if abs(coords_a[0] - coords_b[0]) > 1 or abs(coords_a[1] - coords_b[1]) > 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# def spangram_valid(word_coords:list[list[tuple[int,int]]], direction: str):\n",
    "#     first, last = word_coords[0], word_coords[-1]\n",
    "#     if direction == \"ltr\":\n",
    "#         return first[1] == 0 and last[1] == 5\n",
    "#     else:\n",
    "#         return first[0] == 0 and last[0] == 7\n",
    "\n",
    "# METHOD 2\n",
    "def spangram_valid(word_coords:list[tuple[int,int]], direction: str):\n",
    "    if direction == \"ltr\":\n",
    "        return 0 in [coord[1] for coord in word_coords] and 5 in [coord[1] for coord in word_coords]\n",
    "    else:\n",
    "        return 0 in [coord[0] for coord in word_coords] and 7 in [coord[0] for coord in word_coords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_grid(letter_coords, words, n):\n",
    "    letter_coords_cpy = [word[:] for word in letter_coords]\n",
    "    shuffles = 0\n",
    "\n",
    "    while shuffles < n:\n",
    "        a_coord = random.randint(0, 7), random.randint(0, 5)\n",
    "        a_letter_idx, a_letter, a_word_idx, a_word = get_word_letter_idx(letter_coords_cpy, a_coord, words)\n",
    "\n",
    "        b_candidate_coords = []\n",
    "        for i in range(-1,2):\n",
    "            row = a_coord[0] + i\n",
    "            if row < 0 or row >= 8:\n",
    "                continue\n",
    "            for j in range(-1,2):\n",
    "                col = a_coord[1] + j\n",
    "                if col < 0 or col >= 6 or a_coord == (row, col):\n",
    "                    continue\n",
    "\n",
    "                b_candidate_coords.append((row, col))\n",
    "        \n",
    "        random.shuffle(b_candidate_coords)\n",
    "        for b_coord in b_candidate_coords:\n",
    "            b_letter_idx, b_letter, b_word_idx, b_word = get_word_letter_idx(letter_coords_cpy, b_coord, chosen_words)\n",
    "            if a_word_idx == b_word_idx:\n",
    "                possible_word_coords = [item[:] for item in letter_coords_cpy[a_word_idx]]\n",
    "                possible_word_coords[a_letter_idx] = b_coord\n",
    "                possible_word_coords[b_letter_idx] = a_coord\n",
    "                if a_word_idx == spangram_idx and not spangram_valid(possible_word_coords, spangram_direction):\n",
    "                    continue\n",
    "                if check_word_continuity(possible_word_coords):\n",
    "                    letter_coords_cpy[a_word_idx] = possible_word_coords\n",
    "                    # print(f\"swapping: {a_coord, b_coord} in same word\")\n",
    "                    shuffles += 1\n",
    "                    break\n",
    "            else:\n",
    "                possible_a_word_coords = letter_coords_cpy[a_word_idx][:]\n",
    "                possible_a_word_coords[a_letter_idx] = b_coord\n",
    "\n",
    "                possible_b_word_coords = letter_coords_cpy[b_word_idx][:]\n",
    "                possible_b_word_coords[b_letter_idx] = a_coord\n",
    "\n",
    "                if a_word_idx == spangram_idx and not spangram_valid(possible_a_word_coords, spangram_direction):\n",
    "                    continue\n",
    "\n",
    "                if b_word_idx == spangram_idx and not spangram_valid(possible_b_word_coords, spangram_direction):\n",
    "                    continue\n",
    "\n",
    "                if check_word_continuity(possible_a_word_coords) and check_word_continuity(possible_b_word_coords):\n",
    "                    letter_coords_cpy[a_word_idx] = possible_a_word_coords\n",
    "                    letter_coords_cpy[b_word_idx] = possible_b_word_coords\n",
    "                    # print(f\"swapping: {a_coord, b_coord} in different words\")\n",
    "                    shuffles += 1\n",
    "                    break\n",
    "    return letter_coords_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_letter_coords = shuffle_grid(coords, chosen_words, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0), (0, 1), (0, 2), (1, 3), (2, 4)],\n",
       " [(1, 0), (1, 1), (1, 2), (0, 3), (0, 4), (0, 5), (1, 5)],\n",
       " [(2, 5),\n",
       "  (1, 4),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (3, 3),\n",
       "  (2, 2),\n",
       "  (3, 1),\n",
       "  (2, 1),\n",
       "  (2, 0),\n",
       "  (3, 0)],\n",
       " [(5, 0), (4, 0), (4, 1), (4, 2), (3, 2), (4, 3)],\n",
       " [(6, 1),\n",
       "  (6, 2),\n",
       "  (5, 1),\n",
       "  (5, 2),\n",
       "  (6, 3),\n",
       "  (5, 3),\n",
       "  (6, 4),\n",
       "  (5, 4),\n",
       "  (5, 5),\n",
       "  (4, 5),\n",
       "  (4, 4),\n",
       "  (3, 5)],\n",
       " [(7, 0), (6, 0), (7, 1), (7, 2), (7, 3), (7, 4), (6, 5), (7, 5)]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_letter_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [[\"\" for col in range(6)] for row in range(8)]\n",
    "for word_coords, word in zip(new_letter_coords, chosen_words):\n",
    "    for letter_coord, letter in zip(word_coords, word):\n",
    "        grid[letter_coord[0]][letter_coord[1]] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['p', 'u', 'l', 't', 'a', 'g'],\n",
       " ['f', 'o', 'o', 's', 'e', 'e'],\n",
       " ['g', 'n', 'd', 'c', 'e', 'r'],\n",
       " ['s', 'i', 'e', 'r', 'o', 'y'],\n",
       " ['l', 'i', 'd', 's', 'c', 'n'],\n",
       " ['s', 'a', 'n', 'p', 'r', 'e'],\n",
       " ['r', 't', 'r', 's', 'a', 'l'],\n",
       " ['a', 'r', 'i', 'v', 'a', 's']]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p  u  l  t  a  g\n",
      "\n",
      "f  o  o  s  e  e\n",
      "\n",
      "g  n  d  c  e  r\n",
      "\n",
      "s  i  e  r  o  y\n",
      "\n",
      "l  i  d  s  c  n\n",
      "\n",
      "s  a  n  p  r  e\n",
      "\n",
      "r  t  r  s  a  l\n",
      "\n",
      "a  r  i  v  a  s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([\"  \".join(row) for row in grid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spangram_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
