{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import pickle\n",
    "from scipy.spatial import KDTree\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_cont_set(word, n):\n",
    "    n_letters_word = set()\n",
    "    for i in range(len(word) - n + 1):\n",
    "        n_letters_word.add(word[i:i+n])\n",
    "    return n_letters_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shares_n_cont_letters(a: str, b: str, n: int):\n",
    "    n_letters_a = set()\n",
    "    for i in range(len(a) - n + 1):\n",
    "        n_letters_a.add(a[i:i+n])\n",
    "\n",
    "    for i in range(len(b) - n + 1):\n",
    "        if b[i:i+n] in n_letters_a:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_grid(grid):\n",
    "    return [[tuple(item) for item in row] for row in np.rot90(np.array(grid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fadil/Code/Strands-Game-Generator/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = FlagModel('BAAI/bge-small-en-v1.5',\n",
    "                  query_instruction_for_retrieval=\"Generate a representation for this word for retrieving related words:\",\n",
    "                  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.txt\") as f:\n",
    "    words = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 1823/1823 [05:50<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466550, 384)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Photography\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1000 most relevant words/phrases\n",
    "dd, ii = tree.query(query_embedding, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose pangrammables\n",
    "pangrammable = []\n",
    "for i in ii:\n",
    "    candidate = words[i].strip()\n",
    "    candidate_alpha_only = \"\".join([char for char in candidate if char.isalpha()])\n",
    "    if 6 <= len(candidate_alpha_only) <= 13 and candidate.count(\"-\") == 1:\n",
    "        pangrammable.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sea-framing'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangram = random.choice(pangrammable[:100])\n",
    "pangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "subembeddings = [embeddings[i] for i in ii]\n",
    "subwords = [words[i] for i in ii]\n",
    "subtree = KDTree(subembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1000 most relevant words/phrases\n",
    "ddd, iii = subtree.query(model.encode(pangram), k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates: list[str] = []\n",
    "n = 4\n",
    "candidate_n_cont_pool: set[str] = set()\n",
    "for i in iii:\n",
    "    word = subwords[i].strip().lower()\n",
    "    word_set = generate_n_cont_set(word, n)\n",
    "    unique = True\n",
    "    for item in word_set:\n",
    "        if item in candidate_n_cont_pool:\n",
    "            unique = False\n",
    "            break\n",
    "    if unique:\n",
    "        candidates.append(word)\n",
    "        candidate_n_cont_pool.update(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sea-framing',\n",
       " 'oceanographies',\n",
       " 'photofinishing',\n",
       " 'picture-hanging',\n",
       " 'watercolour',\n",
       " 'artwork',\n",
       " 'raying',\n",
       " 'scenes',\n",
       " 'portfolio',\n",
       " 'stoving',\n",
       " 'canons',\n",
       " 'imagery',\n",
       " 'painting',\n",
       " 'optics',\n",
       " 'shadings',\n",
       " 'foregallery',\n",
       " 'captivities',\n",
       " 'shutters',\n",
       " 'landscape',\n",
       " 'lensing',\n",
       " 'filmizing',\n",
       " 'cannon-shot',\n",
       " 'magnification',\n",
       " 'visually',\n",
       " 'techniques',\n",
       " 'aerial',\n",
       " 'piccaninnies',\n",
       " 'backdrop',\n",
       " 'close-up',\n",
       " 'vision-directed',\n",
       " 'outdoor',\n",
       " 'artistic',\n",
       " 'multicamerate',\n",
       " 'art',\n",
       " 'monocular',\n",
       " 'perspectively',\n",
       " 'outside',\n",
       " 'semiexposed',\n",
       " 'piceous',\n",
       " 'short-cropped',\n",
       " 'retouches',\n",
       " 'picoted',\n",
       " 'reflectance',\n",
       " 'montages',\n",
       " 'kodaking',\n",
       " 'shoots',\n",
       " 'tripodial',\n",
       " 'saliencies',\n",
       " 'pixels',\n",
       " 'art.',\n",
       " 'stills',\n",
       " 'exhibited',\n",
       " 'thumbnails',\n",
       " 'camaraderies',\n",
       " 'prints',\n",
       " 'panoramas',\n",
       " 'cams',\n",
       " 'pic']"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the candidates into plain words and phrases\n",
    "plain_words = []\n",
    "phrases = []\n",
    "for candidate in candidates:\n",
    "    if len(candidate) <= 3:\n",
    "        continue\n",
    "    if candidate.isalpha():\n",
    "        plain_words.append(candidate)\n",
    "    else:\n",
    "        phrases.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oceanographies',\n",
       " 'photofinishing',\n",
       " 'watercolour',\n",
       " 'artwork',\n",
       " 'raying',\n",
       " 'scenes',\n",
       " 'portfolio',\n",
       " 'stoving',\n",
       " 'canons',\n",
       " 'imagery',\n",
       " 'painting',\n",
       " 'optics',\n",
       " 'shadings',\n",
       " 'foregallery',\n",
       " 'captivities',\n",
       " 'shutters',\n",
       " 'landscape',\n",
       " 'lensing',\n",
       " 'filmizing',\n",
       " 'magnification',\n",
       " 'visually',\n",
       " 'techniques',\n",
       " 'aerial',\n",
       " 'piccaninnies',\n",
       " 'backdrop',\n",
       " 'outdoor',\n",
       " 'artistic',\n",
       " 'multicamerate',\n",
       " 'monocular',\n",
       " 'perspectively',\n",
       " 'outside',\n",
       " 'semiexposed',\n",
       " 'piceous',\n",
       " 'retouches',\n",
       " 'picoted',\n",
       " 'reflectance',\n",
       " 'montages',\n",
       " 'kodaking',\n",
       " 'shoots',\n",
       " 'tripodial',\n",
       " 'saliencies',\n",
       " 'pixels',\n",
       " 'stills',\n",
       " 'exhibited',\n",
       " 'thumbnails',\n",
       " 'camaraderies',\n",
       " 'prints',\n",
       " 'panoramas',\n",
       " 'cams']"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_lengths = [len(plain_word) for plain_word in plain_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seaframing'"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangram = \"\".join([char for char in pangram if char.isalpha()])\n",
    "pangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = (48 - len(pangram))//4\n",
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = random.choice(list(range(6, max_words + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 48 - len(pangram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = []\n",
    "plain_lengths_cpy = plain_lengths[:]\n",
    "while sum(chosen) != budget:\n",
    "    remaining = budget - sum(chosen)\n",
    "    if sum(chosen) < budget:\n",
    "        if remaining in plain_lengths_cpy:\n",
    "            chosen.append(remaining)\n",
    "            break\n",
    "        else:\n",
    "            new_chosen = random.choice(plain_lengths_cpy)\n",
    "            plain_lengths_cpy.remove(new_chosen)\n",
    "            chosen.append(new_chosen)\n",
    "    elif sum(chosen) > budget:\n",
    "        if (-remaining) in chosen:\n",
    "            chosen.remove(-remaining)\n",
    "            break\n",
    "        else:\n",
    "            for i in range(random.choice([1,1,1,2,2,3])):\n",
    "                to_remove = random.choice(chosen)\n",
    "                chosen.remove(to_remove)\n",
    "                plain_lengths_cpy.append(to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 8, 13]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lens: dict[int, list[str]] = {}\n",
    "for word in plain_words:\n",
    "    word_len = len(word)\n",
    "    if word_len not in word_lens:\n",
    "        word_lens[word_len] = [word]\n",
    "    else:\n",
    "        word_lens[word_len].append(word)\n",
    "\n",
    "chosen_words = [pangram]\n",
    "for length in chosen:\n",
    "    chosen_word = random.choice(word_lens[length])\n",
    "    word_lens[length].remove(chosen_word)\n",
    "    chosen_words.append(chosen_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seaframing', 'pixels', 'semiexposed', 'painting', 'multicamerate']"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pangram) < 8:\n",
    "    pangram_direction = \"ltr\"\n",
    "else:\n",
    "    pangram_direction = random.choice([\"ltr\", \"ttb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ttb'"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangram_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for i in range(8):\n",
    "    row = []\n",
    "    for j in range(6):\n",
    "        row.append((i,j))\n",
    "    grid.append(row)\n",
    "\n",
    "if pangram_direction == \"ttb\":\n",
    "    grid = rotate_grid(grid)\n",
    "coord_lst = grid.pop(0)\n",
    "while len(grid) > 0:\n",
    "    grid = rotate_grid(grid)\n",
    "    coord_lst.extend(grid.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords: list[list[tuple[int,int]]] = []\n",
    "\n",
    "for word in chosen_words:\n",
    "    word_coords = []\n",
    "    for char in word:\n",
    "        word_coords.append(coord_lst.pop(0))\n",
    "    coords.append(word_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_letter_idx(coords, letter_coords, words):\n",
    "    for word_idx, word_coords in enumerate(coords):\n",
    "        if letter_coords in word_coords:\n",
    "            letter_idx = word_coords.index(letter_coords)\n",
    "            word = words[word_idx]\n",
    "            letter = word[letter_idx]\n",
    "            return letter_idx, letter, word_idx, word\n",
    "    print(\"coords:\", coords)\n",
    "    print(\"letter_coords:\", letter_coords)\n",
    "    print(\"words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_continuity(word_coords:list[list[tuple[int,int]]]):\n",
    "    for coords_a, coords_b in zip(word_coords[:-1], word_coords[1:]):\n",
    "        if abs(coords_a[0] - coords_b[0]) > 1 or abs(coords_a[1] - coords_b[1]) > 1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pangram_valid(word_coords:list[list[tuple[int,int]]], direction: str):\n",
    "    first, last = word_coords[0], word_coords[-1]\n",
    "    if direction == \"ltr\":\n",
    "        return first[1] == 0 and last[1] == 5\n",
    "    else:\n",
    "        return first[0] == 0 and last[0] == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_grid(letter_coords, words, n):\n",
    "    letter_coords_cpy = [word[:] for word in letter_coords]\n",
    "    shuffles = 0\n",
    "\n",
    "    while shuffles < n:\n",
    "        a_coord = random.randint(0, 7), random.randint(0, 5)\n",
    "        a_letter_idx, a_letter, a_word_idx, a_word = get_word_letter_idx(letter_coords_cpy, a_coord, words)\n",
    "\n",
    "        b_candidate_coords = []\n",
    "        for i in range(-1,2):\n",
    "            row = a_coord[0] + i\n",
    "            if row < 0 or row >= 8:\n",
    "                continue\n",
    "            for j in range(-1,2):\n",
    "                col = a_coord[1] + j\n",
    "                if col < 0 or col >= 6 or a_coord == (row, col):\n",
    "                    continue\n",
    "\n",
    "                b_candidate_coords.append((row, col))\n",
    "        \n",
    "        random.shuffle(b_candidate_coords)\n",
    "        for b_coord in b_candidate_coords:\n",
    "            b_letter_idx, b_letter, b_word_idx, b_word = get_word_letter_idx(letter_coords_cpy, b_coord, chosen_words)\n",
    "            if a_word_idx == b_word_idx:\n",
    "                possible_word_coords = [item[:] for item in letter_coords_cpy[a_word_idx]]\n",
    "                possible_word_coords[a_letter_idx] = b_coord\n",
    "                possible_word_coords[b_letter_idx] = a_coord\n",
    "                if a_word_idx == 0 and not pangram_valid(possible_word_coords, pangram_direction):\n",
    "                    continue\n",
    "                if check_word_continuity(possible_word_coords):\n",
    "                    letter_coords_cpy[a_word_idx] = possible_word_coords\n",
    "                    # print(f\"swapping: {a_coord, b_coord} in same word\")\n",
    "                    shuffles += 1\n",
    "                    break\n",
    "            else:\n",
    "                possible_a_word_coords = letter_coords_cpy[a_word_idx][:]\n",
    "                possible_a_word_coords[a_letter_idx] = b_coord\n",
    "\n",
    "                possible_b_word_coords = letter_coords_cpy[b_word_idx][:]\n",
    "                possible_b_word_coords[b_letter_idx] = a_coord\n",
    "\n",
    "                if a_word_idx == 0 and not pangram_valid(possible_a_word_coords, pangram_direction):\n",
    "                    continue\n",
    "\n",
    "                if b_word_idx == 0 and not pangram_valid(possible_b_word_coords, pangram_direction):\n",
    "                    continue\n",
    "\n",
    "                if check_word_continuity(possible_a_word_coords) and check_word_continuity(possible_b_word_coords):\n",
    "                    letter_coords_cpy[a_word_idx] = possible_a_word_coords\n",
    "                    letter_coords_cpy[b_word_idx] = possible_b_word_coords\n",
    "                    # print(f\"swapping: {a_coord, b_coord} in different words\")\n",
    "                    shuffles += 1\n",
    "                    break\n",
    "    return letter_coords_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_letter_coords = shuffle_grid(coords, chosen_words, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [[\"\" for col in range(6)] for row in range(8)]\n",
    "for word_coords, word in zip(new_letter_coords, chosen_words):\n",
    "    for letter_coord, letter in zip(word_coords, word):\n",
    "        grid[letter_coord[0]][letter_coord[1]] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['e', 'e', 'x', 'p', 'o', 's'],\n",
       " ['s', 'm', 'i', 'd', 'e', 's'],\n",
       " ['u', 'l', 'i', 'l', 'e', 'a'],\n",
       " ['m', 't', 'e', 'c', 's', 'f'],\n",
       " ['a', 'm', 'a', 'x', 'i', 'r'],\n",
       " ['p', 'i', 'e', 'r', 'a', 'p'],\n",
       " ['g', 't', 'n', 'a', 'm', 'i'],\n",
       " ['i', 'n', 't', 'e', 'n', 'g']]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e  e  x  p  o  s\n",
      "\n",
      "s  m  i  d  e  s\n",
      "\n",
      "u  l  i  l  e  a\n",
      "\n",
      "m  t  e  c  s  f\n",
      "\n",
      "a  m  a  x  i  r\n",
      "\n",
      "p  i  e  r  a  p\n",
      "\n",
      "g  t  n  a  m  i\n",
      "\n",
      "i  n  t  e  n  g\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([\"  \".join(row) for row in grid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seaframing', 'pixels', 'semiexposed', 'painting', 'multicamerate']"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
